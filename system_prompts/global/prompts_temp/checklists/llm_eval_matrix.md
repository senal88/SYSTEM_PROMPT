# üìä LLM EVAL MATRIX - Avalia√ß√£o de Resposta Cross-Model

**Vers√£o:** 1.0.0
**Data:** 28 de Novembro de 2025
**Status:** Ativo

---

## üéØ Objetivo

Avaliar a qualidade e consist√™ncia de prompts atrav√©s de m√∫ltiplos modelos LLM, garantindo interpreta√ß√£o universal e resultados consistentes.

---

## üìã Matriz de Avalia√ß√£o

### Crit√©rios de Avalia√ß√£o

| Crit√©rio | Descri√ß√£o | Peso |
|----------|-----------|------|
| **Precis√£o** | Resposta correta e t√©cnica | 25% |
| **Completude** | Todas as informa√ß√µes solicitadas | 20% |
| **Clareza** | Linguagem clara e compreens√≠vel | 15% |
| **Consist√™ncia** | Mesmo prompt produz resultados similares | 20% |
| **Relev√¢ncia** | Resposta relevante ao contexto | 10% |
| **Formato** | Segue formato solicitado | 10% |

### Escala de Pontua√ß√£o

- **5 - Excelente:** Atende completamente o crit√©rio
- **4 - Muito Bom:** Atende bem o crit√©rio com pequenas ressalvas
- **3 - Bom:** Atende o crit√©rio de forma satisfat√≥ria
- **2 - Regular:** Atende parcialmente o crit√©rio
- **1 - Insuficiente:** N√£o atende o crit√©rio adequadamente

---

## üîç Modelos para Teste

### CLI / Terminal
- [ ] Shell scripts (bash/zsh)
- [ ] MCP agents
- [ ] Terminal automation

### IDE Extensions
- [ ] Cursor 2.x
- [ ] VSCode Copilot
- [ ] JetBrains AI
- [ ] Raycast AI

### Offline LLMs
- [ ] Ollama (modelos locais)
- [ ] LM Studio
- [ ] llama.cpp
- [ ] GPTQ models

### Web Platforms
- [ ] ChatGPT Plus 5.1
- [ ] Claude Code (Sonnet/Opus)
- [ ] Gemini Pro
- [ ] Perplexity Pro

### Desktop LLMs
- [ ] Aplicativos macOS
- [ ] Aplicativos Windows
- [ ] Aplicativos Linux

### Multi-Agent
- [ ] Coordena√ß√£o entre modelos
- [ ] Pipeline de agentes
- [ ] Orquestra√ß√£o

---

## üìä Template de Avalia√ß√£o

```markdown
# Avalia√ß√£o: [NOME_DO_PROMPT]

## Informa√ß√µes
- **Prompt ID:** [ID]
- **Vers√£o:** [vers√£o]
- **Data:** [data]
- **Avaliador:** [nome]

## Testes por Modelo

### [MODELO_1]
- **Precis√£o:** [1-5] - [coment√°rios]
- **Completude:** [1-5] - [coment√°rios]
- **Clareza:** [1-5] - [coment√°rios]
- **Consist√™ncia:** [1-5] - [coment√°rios]
- **Relev√¢ncia:** [1-5] - [coment√°rios]
- **Formato:** [1-5] - [coment√°rios]
- **Pontua√ß√£o Total:** [X/30]
- **Notas:** [observa√ß√µes]

### [MODELO_2]
[...]

## An√°lise Comparativa

### Pontos Fortes
- [lista de pontos fortes]

### Pontos de Melhoria
- [lista de pontos de melhoria]

### Inconsist√™ncias Identificadas
- [lista de inconsist√™ncias]

## Recomenda√ß√µes
- [recomenda√ß√µes espec√≠ficas]

## Decis√£o
- [ ] Aprovado para produ√ß√£o
- [ ] Requer refinamento
- [ ] Requer revis√£o completa
```

---

## üîÑ Processo de Avalia√ß√£o

### 1. Prepara√ß√£o

- [ ] Prompt no est√°gio 04 (pr√©-release)
- [ ] Checklist de lifecycle completo
- [ ] Ambiente de teste configurado
- [ ] Modelos selecionados

### 2. Execu√ß√£o

- [ ] Testar em cada modelo selecionado
- [ ] Documentar resultados
- [ ] Comparar respostas
- [ ] Identificar padr√µes

### 3. An√°lise

- [ ] Calcular pontua√ß√µes
- [ ] Identificar inconsist√™ncias
- [ ] Analisar pontos fortes/fracos
- [ ] Gerar recomenda√ß√µes

### 4. Decis√£o

- [ ] Aprovar para produ√ß√£o
- [ ] Solicitar refinamento
- [ ] Documentar decis√£o

---

## üìà M√©tricas de Sucesso

### Crit√©rios de Aprova√ß√£o

- **Pontua√ß√£o M√©dia:** ‚â• 4.0 (Muito Bom)
- **Consist√™ncia:** Desvio padr√£o ‚â§ 0.5
- **Cobertura:** Testado em ‚â• 3 categorias diferentes
- **Sem Falhas Cr√≠ticas:** Nenhum crit√©rio com pontua√ß√£o < 2

### N√≠veis de Qualidade

- **Excelente:** M√©dia ‚â• 4.5, consist√™ncia alta
- **Muito Bom:** M√©dia ‚â• 4.0, consist√™ncia boa
- **Bom:** M√©dia ‚â• 3.5, consist√™ncia aceit√°vel
- **Requer Melhoria:** M√©dia < 3.5 ou inconsist√™ncias significativas

---

## üîó Integra√ß√£o com Lifecycle

Esta avalia√ß√£o deve ser realizada:

1. **Antes da promo√ß√£o para produ√ß√£o**
2. **Ap√≥s refinamentos significativos**
3. **Periodicamente para prompts em produ√ß√£o**

---

**Vers√£o:** 1.0.0
**√öltima Atualiza√ß√£o:** 28 de Novembro de 2025
**Status:** Ativo

