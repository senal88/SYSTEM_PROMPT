#!/bin/bash

# @raycast.title IA: Revisar C√≥digo
# @raycast.description Revisa c√≥digo selecionado usando IA (Ollama/HuggingFace/OpenAI)
# @raycast.mode fullOutput
# @raycast.icon üîç
# @raycast.argument1 { "type": "text", "placeholder": "C√≥digo para revisar" }
# @raycast.argument2 { "type": "dropdown", "placeholder": "Provedor IA", "data": "[\"Ollama (Local)\", \"HuggingFace\", \"OpenAI\", \"Gemini\", \"Auto\"]" }

# Configura√ß√µes
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
RAYCAST_DIR="$(dirname "$(dirname "$SCRIPT_DIR")")"
CONFIG_DIR="$RAYCAST_DIR/config"

# Carregar configura√ß√µes
if [ -f "$CONFIG_DIR/ai-config.env" ]; then
    source "$CONFIG_DIR/ai-config.env"
fi

# Configura√ß√µes padr√£o
OLLAMA_HOST=${OLLAMA_HOST:-"http://localhost:11434"}
DEFAULT_MODEL=${DEFAULT_MODEL:-"llama3"}
CODE_MODEL=${CODE_MODEL:-"codellama"}

# Par√¢metros
CODE="$1"
PROVIDER="${2:-Auto}"

# Prompt para revis√£o de c√≥digo (usando template do seu sistema)
REVIEW_PROMPT="Voc√™ √© um revisor de c√≥digo experiente. Analise o seguinte c√≥digo e forne√ßa:

1. **Qualidade Geral**: Avalie a legibilidade, estrutura e organiza√ß√£o
2. **Bugs Potenciais**: Identifique poss√≠veis erros ou problemas
3. **Performance**: Sugest√µes de otimiza√ß√£o
4. **Seguran√ßa**: Vulnerabilidades de seguran√ßa
5. **Melhores Pr√°ticas**: Sugest√µes para seguir padr√µes da ind√∫stria
6. **Refatora√ß√£o**: Sugest√µes de melhoria

C√≥digo para revisar:
\`\`\`
$CODE
\`\`\`

Responda em formato estruturado e seja espec√≠fico com exemplos de c√≥digo quando necess√°rio."

# Fun√ß√£o para chamar Ollama
call_ollama() {
    local model="$1"
    local prompt="$2"
    
    curl -s "$OLLAMA_HOST/api/generate" \
        -X POST \
        -H "Content-Type: application/json" \
        -d "{
            \"model\": \"$model\",
            \"prompt\": \"$prompt\",
            \"stream\": false,
            \"options\": {
                \"temperature\": 0.3,
                \"num_predict\": 2000
            }
        }" | jq -r '.response'
}

# Fun√ß√£o para chamar Hugging Face
call_huggingface() {
    local prompt="$1"
    
    if [ -z "$HUGGINGFACE_API_KEY" ]; then
        echo "‚ùå Hugging Face API key n√£o configurada"
        return 1
    fi
    
    curl -s "https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3-8B-Instruct" \
        -X POST \
        -H "Authorization: Bearer $HUGGINGFACE_API_KEY" \
        -H "Content-Type: application/json" \
        -d "{
            \"inputs\": \"$prompt\",
            \"parameters\": {
                \"temperature\": 0.3,
                \"max_new_tokens\": 2000,
                \"return_full_text\": false
            }
        }" | jq -r '.[0].generated_text'
}

# Fun√ß√£o para chamar OpenAI
call_openai() {
    local prompt="$1"
    
    if [ -z "$OPENAI_API_KEY" ]; then
        echo "‚ùå OpenAI API key n√£o configurada"
        return 1
    fi
    
    curl -s "https://api.openai.com/v1/chat/completions" \
        -X POST \
        -H "Authorization: Bearer $OPENAI_API_KEY" \
        -H "Content-Type: application/json" \
        -d "{
            \"model\": \"gpt-3.5-turbo\",
            \"messages\": [
                {\"role\": \"system\", \"content\": \"Voc√™ √© um revisor de c√≥digo experiente.\"},
                {\"role\": \"user\", \"content\": \"$prompt\"}
            ],
            \"temperature\": 0.3,
            \"max_tokens\": 2000
        }" | jq -r '.choices[0].message.content'
}

# Fun√ß√£o para chamar Gemini
call_gemini() {
    local prompt="$1"
    
    if [ -z "$GEMINI_API_KEY" ]; then
        echo "‚ùå Gemini API key n√£o configurada"
        return 1
    fi
    
    curl -s "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=$GEMINI_API_KEY" \
        -X POST \
        -H "Content-Type: application/json" \
        -d "{
            \"contents\": [
                {
                    \"role\": \"user\",
                    \"parts\": [{\"text\": \"$prompt\"}]
                }
            ],
            \"generationConfig\": {
                \"temperature\": 0.3,
                \"maxOutputTokens\": 2000
            }
        }" | jq -r '.candidates[0].content.parts[0].text'
}

# Verificar se o c√≥digo foi fornecido
if [ -z "$CODE" ]; then
    echo "‚ùå Por favor, forne√ßa o c√≥digo para revisar"
    exit 1
fi

echo "üîç Iniciando revis√£o de c√≥digo com IA..."
echo "ü§ñ Provedor selecionado: $PROVIDER"
echo ""

# Executar baseado no provedor selecionado
case "$PROVIDER" in
    "Ollama (Local)")
        echo "ü§ñ Usando Ollama (modelo local)..."
        if curl -s "$OLLAMA_HOST/api/tags" > /dev/null 2>&1; then
            RESULT=$(call_ollama "$CODE_MODEL" "$REVIEW_PROMPT")
            if [ $? -eq 0 ] && [ -n "$RESULT" ]; then
                echo "‚úÖ Revis√£o conclu√≠da usando Ollama ($CODE_MODEL)"
                echo ""
                echo "$RESULT"
                exit 0
            fi
        fi
        echo "‚ùå Ollama n√£o dispon√≠vel"
        ;;
    
    "HuggingFace")
        echo "üåê Usando Hugging Face..."
        RESULT=$(call_huggingface "$REVIEW_PROMPT")
        if [ $? -eq 0 ] && [ -n "$RESULT" ]; then
            echo "‚úÖ Revis√£o conclu√≠da usando Hugging Face"
            echo ""
            echo "$RESULT"
            exit 0
        fi
        echo "‚ùå Hugging Face falhou"
        ;;
    
    "OpenAI")
        echo "‚òÅÔ∏è Usando OpenAI..."
        RESULT=$(call_openai "$REVIEW_PROMPT")
        if [ $? -eq 0 ] && [ -n "$RESULT" ]; then
            echo "‚úÖ Revis√£o conclu√≠da usando OpenAI"
            echo ""
            echo "$RESULT"
            exit 0
        fi
        echo "‚ùå OpenAI falhou"
        ;;
    
    "Gemini")
        echo "üîÆ Usando Gemini..."
        RESULT=$(call_gemini "$REVIEW_PROMPT")
        if [ $? -eq 0 ] && [ -n "$RESULT" ]; then
            echo "‚úÖ Revis√£o conclu√≠da usando Gemini"
            echo ""
            echo "$RESULT"
            exit 0
        fi
        echo "‚ùå Gemini falhou"
        ;;
    
    "Auto")
        echo "üîÑ Modo autom√°tico - tentando provedores em ordem..."
        
        # Tentar Ollama primeiro (local)
        if curl -s "$OLLAMA_HOST/api/tags" > /dev/null 2>&1; then
            RESULT=$(call_ollama "$CODE_MODEL" "$REVIEW_PROMPT")
            if [ $? -eq 0 ] && [ -n "$RESULT" ]; then
                echo "‚úÖ Revis√£o conclu√≠da usando Ollama ($CODE_MODEL)"
                echo ""
                echo "$RESULT"
                exit 0
            fi
        fi
        
        # Tentar Hugging Face
        if [ -n "$HUGGINGFACE_API_KEY" ]; then
            RESULT=$(call_huggingface "$REVIEW_PROMPT")
            if [ $? -eq 0 ] && [ -n "$RESULT" ]; then
                echo "‚úÖ Revis√£o conclu√≠da usando Hugging Face"
                echo ""
                echo "$RESULT"
                exit 0
            fi
        fi
        
        # Tentar OpenAI
        if [ -n "$OPENAI_API_KEY" ]; then
            RESULT=$(call_openai "$REVIEW_PROMPT")
            if [ $? -eq 0 ] && [ -n "$RESULT" ]; then
                echo "‚úÖ Revis√£o conclu√≠da usando OpenAI"
                echo ""
                echo "$RESULT"
                exit 0
            fi
        fi
        
        # Tentar Gemini
        if [ -n "$GEMINI_API_KEY" ]; then
            RESULT=$(call_gemini "$REVIEW_PROMPT")
            if [ $? -eq 0 ] && [ -n "$RESULT" ]; then
                echo "‚úÖ Revis√£o conclu√≠da usando Gemini"
                echo ""
                echo "$RESULT"
                exit 0
            fi
        fi
        
        echo "‚ùå Todos os provedores falharam"
        ;;
esac

echo ""
echo "üîß Verifica√ß√µes necess√°rias:"
echo "   - Ollama: brew services start ollama && ollama pull codellama"
echo "   - API Keys: Configure em $CONFIG_DIR/ai-config.env"
echo "   - Conex√£o: Verifique sua conex√£o com a internet"
exit 1

